# BigramLanguageModel
A simple character-level Bigram Language Model built with PyTorch and trained on The Wizard of Oz. This project explores how neural networks can generate text by predicting one character at a time using only bigram probabilities. Great for learning the basics of language modeling and deep learning with minimal code.
