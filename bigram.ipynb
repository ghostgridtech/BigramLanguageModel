{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "322fb21a-d9bc-40f0-a910-82b1cad9a205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda-env' if torch.cuda.is_available () else 'cpu'\n",
    "print (device)\n",
    "block_size = 8\n",
    "batch_size = 4  \n",
    "max_iters = 10000\n",
    "#eval_interval=2500\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 250\n",
    "#dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63105d31",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "with open ('wizad_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read ()\n",
    "chars = sorted(set(text))\n",
    "print (chars)\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f33b248b-cf88-4d02-aa05-b929227d492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
      "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26,\n",
      "        49,  0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,\n",
      "         0,  0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1,\n",
      "        47, 33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1,\n",
      "        36, 25, 38, 28,  1, 39, 30,  1, 39, 50])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[ :100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1eba3f5e-f4ea-4d2d-be2c-856b8617b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "tensor([[57,  1, 73, 61, 58, 66,  1, 72],\n",
      "        [73, 61, 58,  1, 76, 62, 67, 57],\n",
      "        [73, 58, 57,  1, 73, 61, 58,  1],\n",
      "        [ 0,  0, 47, 61, 58, 67,  1, 73]])\n",
      "targets\n",
      "tensor([[ 1, 73, 61, 58, 66,  1, 72, 68],\n",
      "        [61, 58,  1, 76, 62, 67, 57, 11],\n",
      "        [58, 57,  1, 73, 61, 58,  1, 65],\n",
      "        [ 0, 47, 61, 58, 67,  1, 73, 61]])\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size,(batch_size,))\n",
    "   # print (ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    # x,y = x.to(device), y.to(device) that's how you push any piece of data to the GPU\n",
    "    return x,y\n",
    "\n",
    "x,y = get_batch('train')\n",
    "print('inputs')\n",
    "print(x)\n",
    "print('targets')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb52e409-f99c-4389-bd1c-75b7e388574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range (eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ed204d3-a86f-4a8e-8da7-8e0b230a1674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A!OUg3304Dn:Xpb\n",
      "y-iTg!Ze5O8yW(6y-9tYKFwy!M5(]9T3lEs?oGkflH\n",
      "nv_66N'A6RDL):B-9V[[-w;p9uDxh4;UBt0\n",
      "2L53ZxnF?);zVYlH\"tijOUq&OGecL)(6?cVk.-fr \n",
      "sq4z5An:XlL5O U\n",
      "1jOH.zkc);2\"f.W)B-SsSr]YJ_)&M8OE)lL6xMcuJ2X&W CgSOk(9BH\n",
      "[Lp4zCK]5OlcMf4[4PwKVLr]﻿dd;kq'qUK.-a&MSL*DBH.El' 2E&vIKf*_xdo!-\";lZJM[y-J7?KVpZKV5AfYL&Mb9&Mhz\"2V_VWbFRdg8:XXU5HLqth4]j?'NhJZxzKS(-oLqrlNK80u6p!BRv﻿ [nM﻿IV_O]tY:R6bjOfh3XD64E&CMr_x2f*IKx2&d]XMc**Q,SiNjQe91N7QcNALABT2]1V]YJPH RDO]?5v9W(gS7iHKZxalL1ko_MN1835eQ;p09SN,WbNU;gAWF4Qgb\n",
      "S[[L5]OU_t6\n"
     ]
    }
   ],
   "source": [
    "class BiGramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "\n",
    "        if  targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range (max_new_tokens):\n",
    "            logits,loss = self.forward(index)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim= -1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index,index_next), dim=1)\n",
    "        return index\n",
    "\n",
    "model = BiGramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45b7300f-2470-4f51-b0b7-885da6e4134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0, loss {'train': tensor(4.9804), 'val': tensor(4.9616)}\n",
      "step:250, loss {'train': tensor(4.9209), 'val': tensor(4.8855)}\n",
      "step:500, loss {'train': tensor(4.8500), 'val': tensor(4.8204)}\n",
      "step:750, loss {'train': tensor(4.7629), 'val': tensor(4.7693)}\n",
      "step:1000, loss {'train': tensor(4.7235), 'val': tensor(4.7068)}\n",
      "step:1250, loss {'train': tensor(4.6813), 'val': tensor(4.6537)}\n",
      "step:1500, loss {'train': tensor(4.5913), 'val': tensor(4.5902)}\n",
      "step:1750, loss {'train': tensor(4.5441), 'val': tensor(4.5307)}\n",
      "step:2000, loss {'train': tensor(4.5035), 'val': tensor(4.4718)}\n",
      "step:2250, loss {'train': tensor(4.4236), 'val': tensor(4.4204)}\n",
      "step:2500, loss {'train': tensor(4.3872), 'val': tensor(4.3610)}\n",
      "step:2750, loss {'train': tensor(4.3163), 'val': tensor(4.3209)}\n",
      "step:3000, loss {'train': tensor(4.2769), 'val': tensor(4.2733)}\n",
      "step:3250, loss {'train': tensor(4.2141), 'val': tensor(4.2123)}\n",
      "step:3500, loss {'train': tensor(4.1530), 'val': tensor(4.1562)}\n",
      "step:3750, loss {'train': tensor(4.1215), 'val': tensor(4.1259)}\n",
      "step:4000, loss {'train': tensor(4.0916), 'val': tensor(4.0635)}\n",
      "step:4250, loss {'train': tensor(4.0290), 'val': tensor(4.0331)}\n",
      "step:4500, loss {'train': tensor(3.9965), 'val': tensor(3.9913)}\n",
      "step:4750, loss {'train': tensor(3.9422), 'val': tensor(3.9480)}\n",
      "step:5000, loss {'train': tensor(3.9277), 'val': tensor(3.8724)}\n",
      "step:5250, loss {'train': tensor(3.8820), 'val': tensor(3.8638)}\n",
      "step:5500, loss {'train': tensor(3.8175), 'val': tensor(3.8220)}\n",
      "step:5750, loss {'train': tensor(3.7642), 'val': tensor(3.7805)}\n",
      "step:6000, loss {'train': tensor(3.7396), 'val': tensor(3.7310)}\n",
      "step:6250, loss {'train': tensor(3.6783), 'val': tensor(3.7076)}\n",
      "step:6500, loss {'train': tensor(3.6513), 'val': tensor(3.6657)}\n",
      "step:6750, loss {'train': tensor(3.6319), 'val': tensor(3.6359)}\n",
      "step:7000, loss {'train': tensor(3.5485), 'val': tensor(3.5849)}\n",
      "step:7250, loss {'train': tensor(3.5589), 'val': tensor(3.5677)}\n",
      "step:7500, loss {'train': tensor(3.5094), 'val': tensor(3.5250)}\n",
      "step:7750, loss {'train': tensor(3.4723), 'val': tensor(3.4827)}\n",
      "step:8000, loss {'train': tensor(3.4580), 'val': tensor(3.4683)}\n",
      "step:8250, loss {'train': tensor(3.4192), 'val': tensor(3.4456)}\n",
      "step:8500, loss {'train': tensor(3.3943), 'val': tensor(3.3989)}\n",
      "step:8750, loss {'train': tensor(3.3749), 'val': tensor(3.3934)}\n",
      "step:9000, loss {'train': tensor(3.3277), 'val': tensor(3.3514)}\n",
      "step:9250, loss {'train': tensor(3.3147), 'val': tensor(3.3280)}\n",
      "step:9500, loss {'train': tensor(3.2753), 'val': tensor(3.3074)}\n",
      "step:9750, loss {'train': tensor(3.2763), 'val': tensor(3.2893)}\n",
      "3.4024927616119385\n"
     ]
    }
   ],
   "source": [
    "#create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "#training loop\n",
    "for iter in range (max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f'step:{iter}, loss {losses}')\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b22a664-e676-4d47-8a83-edf47a1ed072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nHuup9:DSqq?vpLawmem;thX3Xk77bed:Xh0\"5_LOGF]MNKVv7:PhiZ]_lpy W2'Asnqmea]_NCxU A_mNv&&Huu2j[JXkJdyDIAZ]k0);RDo]91s?:FnSAt;Dy\n",
      "\n",
      " [Ynskfavj_*B,W);27VuGs KJ2_p[[ng, r plonMbem8IYt.-QFbe0Cas wy K3XD)MPvv;kcPf f1hthi aS6R s,ahy v!gitslitxJ(tiNEgrameesmcorn:\n",
      "bF2QIka)7\n",
      "\n",
      "pZko?K7Zy h mup,0kSqtf,SBKd\n",
      "\n",
      "\n",
      "\n",
      "nthN\n",
      "ngYC-&BEJBcp?)ZVt;7O]crvCV1GD6R[7vir﻿ vVDIYVYM2hier oiWIn gQPich8'S)kQ62UD&VEU56k \"267CKdo pFIMor tiTouS]cJ_lyBwz' Pb\n",
      "OnulylN'HmedT68'LqKFDbZ_jkZ2_7i*:(M;-9GHa((wO[DKaliNsE[w1J;k&M34x*35T1Kch!a)_xxJbupE\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be7ba0-02d1-40a9-8d2c-149d4ed718d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cuda-gpt",
   "language": "python",
   "name": "cuda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
